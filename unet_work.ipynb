{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import os\n",
    "\n",
    "from datasets import DatasetGenerator, PairedMNISTDataset\n",
    "from helpers import EarlyStopper, classification_run, contrastive_run, unet_run, run_dswd\n",
    "from models import TinyCNN, TinyCNN_Headless, TinyCNN_Head, WrapperModelTrainHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "x_train = mnist_train.data.numpy()\n",
    "y_train = mnist_train.targets.numpy()\n",
    "\n",
    "x_test = mnist_test.data.numpy()\n",
    "y_test = mnist_test.targets.numpy()\n",
    "\n",
    "x_test, x_val, y_test, y_val = tts(\n",
    "    x_test, y_test, test_size=.5, random_state=71\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base - None / Aux - Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"none\"\n",
    "aux = \"skip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_gen: DatasetGenerator = DatasetGenerator(\n",
    "    images = x_train,\n",
    "    labels = y_train,\n",
    "    subset_ratio = .2,\n",
    "    base_ds=base,\n",
    "    aux_ds=aux\n",
    ")\n",
    "\n",
    "base_images_train, base_labels_train = train_ds_gen.build_base_dataset()\n",
    "aux_images_train, aux_labels_train = train_ds_gen.build_aux_dataset()\n",
    "\n",
    "print(f\"Train Dataset Base Size: {len(base_images_train)}\")\n",
    "print(f\"Train Dataset Aux Size: {len(aux_images_train)}\")\n",
    "\n",
    "test_ds_gen: DatasetGenerator = DatasetGenerator(\n",
    "    images = x_test,\n",
    "    labels = y_test,\n",
    "    subset_ratio = .5,\n",
    "    base_ds=base,\n",
    "    aux_ds=aux\n",
    ")\n",
    "\n",
    "base_images_test, base_labels_test = test_ds_gen.build_base_dataset()\n",
    "aux_images_test, aux_labels_test = test_ds_gen.build_aux_dataset()\n",
    "\n",
    "print(f\"Test Dataset Base Size: {len(base_images_test)}\")\n",
    "print(f\"Test Dataset Aux Size: {len(aux_images_test)}\")\n",
    "\n",
    "val_ds_gen: DatasetGenerator = DatasetGenerator(\n",
    "    images = x_val,\n",
    "    labels = y_val,\n",
    "    subset_ratio = .5,\n",
    "    base_ds=base,\n",
    "    aux_ds=aux\n",
    ")\n",
    "\n",
    "base_images_val, base_labels_val = val_ds_gen.build_base_dataset()\n",
    "aux_images_val, aux_labels_val = val_ds_gen.build_aux_dataset()\n",
    "\n",
    "print(f\"Validation Dataset Base Size: {len(base_images_val)}\")\n",
    "print(f\"Validation Dataset Aux Size: {len(aux_images_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset: PairedMNISTDataset = PairedMNISTDataset(\n",
    "    base_images=base_images_train,\n",
    "    base_labels=base_labels_train,\n",
    "    aux_images=aux_images_train,\n",
    "    aux_labels=aux_labels_train\n",
    ")\n",
    "\n",
    "test_dataset: PairedMNISTDataset = PairedMNISTDataset(\n",
    "    base_images=base_images_test,\n",
    "    base_labels=base_labels_test,\n",
    "    aux_images=aux_images_test,\n",
    "    aux_labels=aux_labels_test\n",
    ")\n",
    "\n",
    "val_dataset: PairedMNISTDataset = PairedMNISTDataset(\n",
    "    base_images=base_images_val,\n",
    "    base_labels=base_labels_val,\n",
    "    aux_images=aux_images_val,\n",
    "    aux_labels=aux_labels_val\n",
    ")\n",
    "\n",
    "train_loader: DataLoader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader: DataLoader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "val_loader: DataLoader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"models_unet\"):\n",
    "    os.mkdir(\"models_unet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"models_unet/base_classifier_{base}.pt\"):\n",
    "    num_base_epochs = 20\n",
    "\n",
    "    model = TinyCNN()\n",
    "    model.to(DEVICE)\n",
    "    optimizer = optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    base_early_stopper = EarlyStopper(\n",
    "        patience=5,\n",
    "        min_delta=0\n",
    "    )\n",
    "\n",
    "    base_best = {\n",
    "        \"val_loss\": 1000,\n",
    "        \"val_acc\": 0\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_base_epochs):\n",
    "        train_loss, train_acc = classification_run(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            dataloader=train_loader,\n",
    "            mode=\"base_only\",\n",
    "            device=DEVICE,\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc = classification_run(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            dataloader=val_loader,\n",
    "            mode=\"base_only\",\n",
    "            device=DEVICE,\n",
    "            train=False\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}:\", round(train_loss, 4), round(train_acc*100, 2), round(val_loss, 4), round(val_acc*100, 2))\n",
    "\n",
    "        if val_loss < base_best[\"val_loss\"]:\n",
    "            base_best[\"val_loss\"] = val_loss\n",
    "            base_best[\"val_acc\"] = val_acc\n",
    "            torch.save(model.state_dict(), f\"models_unet/base_classifier_{base}.pt\")\n",
    "\n",
    "        if base_early_stopper(val_loss):\n",
    "            print(\"Stopped\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"models_unet/mixed_classifier_{base}+{aux}.pt\"):\n",
    "    model = TinyCNN()\n",
    "    model.to(DEVICE)\n",
    "    optimizer = optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    base_early_stopper = EarlyStopper(\n",
    "        patience=5,\n",
    "        min_delta=0\n",
    "    )\n",
    "\n",
    "    base_aux_best = {\n",
    "        \"val_loss\": 1000,\n",
    "        \"val_acc\": 0\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_base_epochs):\n",
    "        train_loss, train_acc = classification_run(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            dataloader=train_loader,\n",
    "            mode=\"base_and_aux\",\n",
    "            device=DEVICE,\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc = classification_run(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            dataloader=val_loader,\n",
    "            device=DEVICE,\n",
    "            mode=\"base_only\",\n",
    "            train=False\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}:\", round(train_loss, 4), round(train_acc*100, 2), round(val_loss, 4), round(val_acc*100, 2))\n",
    "\n",
    "        if val_loss < base_aux_best[\"val_loss\"]:\n",
    "            base_aux_best[\"val_loss\"] = val_loss\n",
    "            base_aux_best[\"val_acc\"] = val_acc\n",
    "            torch.save(model.state_dict(), f\"models_unet/mixed_classifier_{base}+{aux}.pt\")\n",
    "\n",
    "        if base_early_stopper(val_loss):\n",
    "            print(\"Stopped\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Contrastive Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Body Training + Temperature Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contrast_epochs = 200\n",
    "temp_range = np.linspace(0.05, .15, 3)\n",
    "best_val_loss = 1000*np.ones(len(temp_range))\n",
    "\n",
    "for i, temp in enumerate(temp_range):\n",
    "    model = TinyCNN_Headless()\n",
    "    proj_head = torch.nn.Linear(32, 128)\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    proj_head.to(DEVICE)\n",
    "\n",
    "    contrast_optimizer = optim.Adam(\n",
    "        list(model.parameters()) + list(proj_head.parameters()),\n",
    "        lr=0.001, \n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "\n",
    "    contrast_early_stopper = EarlyStopper(\n",
    "        patience=10,\n",
    "        min_delta=0\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_contrast_epochs):\n",
    "        train_loss = contrastive_run(\n",
    "            model=model,\n",
    "            proj_head=proj_head,\n",
    "            optimizer=contrast_optimizer,\n",
    "            dataloader=train_loader,\n",
    "            device=DEVICE,\n",
    "            temperature=temp\n",
    "        )\n",
    "\n",
    "        val_loss = contrastive_run(\n",
    "            model=model,\n",
    "            proj_head=proj_head,\n",
    "            optimizer=contrast_optimizer,\n",
    "            dataloader=val_loader,\n",
    "            device=DEVICE,\n",
    "            train=False,\n",
    "            temperature=temp\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val_loss[i]:\n",
    "            best_val_loss[i] = val_loss\n",
    "            torch.save(model.state_dict(), f\"models_unet/contrast_body_{base}+{aux}_{round(temp, 2)}.pt\")\n",
    "            torch.save(proj_head.state_dict(), f\"models_unet/contrast_proj_{base}+{aux}_{round(temp, 2)}.pt\")\n",
    "\n",
    "        if contrast_early_stopper(val_loss):\n",
    "            print(\"\\n\")\n",
    "            print(f\"Best Val Loss ({round(temp, 2)}):\", best_val_loss[i])\n",
    "            break\n",
    "\n",
    "        if (epoch+1 == num_contrast_epochs):\n",
    "            print(\"\\n\")\n",
    "            print(f\"Best Val Loss ({round(temp, 2)}):\", best_val_loss[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Contrastive Learning Head Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_temp = round(temp_range[np.argmin(best_val_loss)], 2)\n",
    "print(f\"Best temp: {best_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class_epochs = 20\n",
    "\n",
    "contrast_body = TinyCNN_Headless()\n",
    "contrast_body.load_state_dict(torch.load(f\"models_unet/contrast_body_{base}+{aux}_{best_temp}.pt\", weights_only=True))\n",
    "\n",
    "class_head = TinyCNN_Head()\n",
    "\n",
    "wrapped_model = WrapperModelTrainHead(\n",
    "    body = contrast_body,\n",
    "    head = class_head\n",
    ")\n",
    "wrapped_model.to(DEVICE)\n",
    "optimizer = optim.Adam(\n",
    "    wrapped_model.head.parameters(),\n",
    "    lr = 0.001,\n",
    "    weight_decay = 1e-5\n",
    ")\n",
    "\n",
    "contrast_early_stopper = EarlyStopper(\n",
    "    patience=5,\n",
    "    min_delta=0\n",
    ")\n",
    "\n",
    "contrast_best = {\n",
    "    \"val_loss\": 1000,\n",
    "    \"val_acc\": 0\n",
    "}\n",
    "\n",
    "for epoch in range(num_class_epochs):\n",
    "    train_loss, train_acc = classification_run(\n",
    "        model=wrapped_model,\n",
    "        optimizer=optimizer,\n",
    "        dataloader=train_loader,\n",
    "        mode=\"base_and_aux\",\n",
    "        device=DEVICE,\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = classification_run(\n",
    "        model=wrapped_model,\n",
    "        optimizer=optimizer,\n",
    "        dataloader=val_loader,\n",
    "        device=DEVICE,\n",
    "        mode=\"base_only\",\n",
    "        train=False\n",
    "    )\n",
    "\n",
    "    print(f\"Epoch {epoch+1}:\", round(train_loss, 4), round(train_acc*100, 2), round(val_loss, 4), round(val_acc*100, 2))\n",
    "\n",
    "    if val_loss < contrast_best[\"val_loss\"]:\n",
    "        contrast_best[\"val_loss\"] = val_loss\n",
    "        contrast_best[\"val_acc\"] = val_acc\n",
    "        torch.save(wrapped_model.state_dict(), f\"models_unet/contrast_classifier_{base}+{aux}.pt\")\n",
    "\n",
    "    if contrast_early_stopper(val_loss):\n",
    "        print(\"\\n\")\n",
    "        print(\"Best Val Loss:\", contrast_best[\"val_loss\"])\n",
    "        print(\"Best Val Acc:\", round(contrast_best[\"val_acc\"]*100, 2))\n",
    "        break\n",
    "\n",
    "    if (epoch+1 == num_class_epochs):\n",
    "        print(\"\\n\")\n",
    "        print(\"Best Val Loss:\", contrast_best[\"val_loss\"])\n",
    "        print(\"Best Val Acc:\", round(contrast_best[\"val_acc\"]*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Accuracies Between Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = TinyCNN()\n",
    "base_model.load_state_dict(torch.load(f\"models_unet/base_classifier_{base}.pt\", weights_only=True))\n",
    "base_model.to(DEVICE)\n",
    "base_loss, base_acc = classification_run(\n",
    "    model=base_model,\n",
    "    optimizer=optimizer,\n",
    "    dataloader=val_loader,\n",
    "    device=DEVICE,\n",
    "    mode=\"base_only\",\n",
    "    train=False\n",
    ")\n",
    "\n",
    "mixed_model = TinyCNN()\n",
    "mixed_model.load_state_dict(torch.load(f\"models_unet/mixed_classifier_{base}+{aux}.pt\", weights_only=True))\n",
    "mixed_model.to(DEVICE)\n",
    "mixed_loss, mixed_acc = classification_run(\n",
    "    model=mixed_model,\n",
    "    optimizer=optimizer,\n",
    "    dataloader=val_loader,\n",
    "    device=DEVICE,\n",
    "    mode=\"base_only\",\n",
    "    train=False\n",
    ")\n",
    "\n",
    "\n",
    "contrast_body = TinyCNN_Headless()\n",
    "contrast_head = TinyCNN_Head()\n",
    "\n",
    "contrast_model = WrapperModelTrainHead(\n",
    "    body=contrast_body,\n",
    "    head=contrast_head\n",
    ")\n",
    "contrast_model.load_state_dict(torch.load(f\"models_unet/contrast_classifier_{base}+{aux}.pt\", weights_only=True))\n",
    "contrast_model.to(DEVICE)\n",
    "\n",
    "contrast_loss, contrast_acc = classification_run(\n",
    "    model=contrast_model,\n",
    "    optimizer=optimizer,\n",
    "    dataloader=val_loader,\n",
    "    device=DEVICE,\n",
    "    mode=\"base_only\",\n",
    "    train=False\n",
    ")\n",
    "\n",
    "print(f\"Base: {round(base_loss, 4)}, {round(base_acc*100, 2)}\")\n",
    "print(f\"Base + Aux: {round(mixed_loss, 4)}, {round(mixed_acc*100, 2)}\")\n",
    "print(f\"Base + Aux: {round(contrast_loss, 4)}, {round(contrast_acc*100, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Latent Space Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = TinyCNN()\n",
    "base_model.load_state_dict(torch.load(f\"models_unet/base_classifier_{base}.pt\", weights_only=True))\n",
    "base_model.eval()\n",
    "\n",
    "mixed_model = TinyCNN()\n",
    "mixed_model.load_state_dict(torch.load(f\"models_unet/mixed_classifier_{base}+{aux}.pt\", weights_only=True))\n",
    "mixed_model.eval()\n",
    "\n",
    "contrast_body = TinyCNN_Headless()\n",
    "contrast_head = TinyCNN_Head()\n",
    "\n",
    "contrast_model = WrapperModelTrainHead(\n",
    "    body=contrast_body,\n",
    "    head=contrast_head\n",
    ")\n",
    "\n",
    "contrast_model.load_state_dict(torch.load(f\"models_unet/contrast_classifier_{base}+{aux}.pt\", weights_only=True))\n",
    "contrast_model.eval()\n",
    "\n",
    "contrast_model.to(DEVICE)\n",
    "base_model.to(DEVICE)\n",
    "mixed_model.to(DEVICE)\n",
    "\n",
    "base_embeds = np.zeros((len(test_dataset), 32))\n",
    "mixed_embeds_base = np.zeros((len(test_dataset), 32))\n",
    "mixed_embeds_aux = np.zeros((len(test_dataset), 32))\n",
    "contrast_embeds_base = np.zeros((len(test_dataset), 32))\n",
    "contrast_embeds_aux = np.zeros((len(test_dataset), 32))\n",
    "labels = np.zeros(len(test_dataset))\n",
    "\n",
    "test_loader.dataset.unique_sources = True\n",
    "\n",
    "for i, (x,y,z) in enumerate(test_loader):\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        base_outputs = base_model(x)[9].cpu().numpy()\n",
    "        mixed_outputs_base = mixed_model(x)[9].cpu().numpy()\n",
    "        mixed_outputs_aux = mixed_model(y)[9].cpu().numpy()\n",
    "        contrast_outputs_base = contrast_model(x)[9].cpu().numpy()\n",
    "        contrast_outputs_aux = contrast_model(y)[9].cpu().numpy()\n",
    "\n",
    "        base_embeds[i*8:i*8+8] = base_outputs\n",
    "        mixed_embeds_base[i*8:i*8+8] = mixed_outputs_base\n",
    "        mixed_embeds_aux[i*8:i*8+8] = mixed_outputs_aux\n",
    "        contrast_embeds_base[i*8:i*8+8] = contrast_outputs_base\n",
    "        contrast_embeds_aux[i*8:i*8+8] = contrast_outputs_aux\n",
    "        labels[i*8:i*8+8] = z.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_labels = np.concatenate((labels*2, labels*2+1))\n",
    "mixed_embeds = np.concatenate((mixed_embeds_base, mixed_embeds_aux))\n",
    "\n",
    "contrast_labels = np.concatenate((labels*2, labels*2+1))\n",
    "contrast_embeds = np.concatenate((contrast_embeds_base, contrast_embeds_aux))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "# Perform t-SNE for all three embedding sets\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "base_tsne = tsne.fit_transform(base_embeds)\n",
    "mixed_tsne = tsne.fit_transform(mixed_embeds)\n",
    "contrast_tsne = tsne.fit_transform(contrast_embeds)\n",
    "\n",
    "# Convert labels to numpy if it's a torch tensor\n",
    "if isinstance(labels, torch.Tensor):\n",
    "    labels = labels.numpy()\n",
    "\n",
    "# Create three subplots side by side\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 8))\n",
    "\n",
    "# Plot for base embeddings\n",
    "scatter1 = ax1.scatter(base_tsne[:, 0], base_tsne[:, 1], c=labels, cmap='tab10', alpha=.7)\n",
    "ax1.set_title(f'Base Model Embeddings (Accuracy: {round(base_acc*100, 2)}%)')\n",
    "ax1.set_xlabel('t-SNE feature 1')\n",
    "ax1.set_ylabel('t-SNE feature 2')\n",
    "cbar = fig.colorbar(scatter1, ax=ax1)\n",
    "ticks = np.arange(0, 10)\n",
    "c_labels = [ \n",
    "    \"0 - Base\",\n",
    "    \"1 - Base\",\n",
    "    \"2 - Base\",\n",
    "    \"3 - Base\",\n",
    "    \"4 - Base\",\n",
    "    \"5 - Base\",\n",
    "    \"6 - Base\",\n",
    "    \"7 - Base\",\n",
    "    \"8 - Base\",\n",
    "    \"9 - Base\",\n",
    "]\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.set_ticklabels(c_labels)\n",
    "cbar.set_label(\"Classes\")\n",
    "\n",
    "tab20 = plt.cm.get_cmap('tab20')\n",
    "color_dict = {i: tab20(i/20) for i in range(20)}\n",
    "\n",
    "scatter2a = ax2.scatter(mixed_tsne[:len(mixed_tsne)//2, 0], mixed_tsne[:len(mixed_tsne)//2, 1], c=[color_dict[label] for label in mixed_labels[:len(mixed_tsne)//2]])\n",
    "scatter2b = ax2.scatter(mixed_tsne[len(mixed_tsne)//2:, 0], mixed_tsne[len(mixed_tsne)//2:, 1], c=[color_dict[label] for label in mixed_labels[len(mixed_tsne)//2:]], marker=\"x\", s=30)\n",
    "ax2.set_title(f'Mixed Model Embeddings (Accuracy: {round(mixed_acc*100, 2)}%)')\n",
    "ax2.set_xlabel('t-SNE feature 1')\n",
    "ax2.set_ylabel('t-SNE feature 2')\n",
    "colors = [color_dict[i] for i in range(20)]\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "bounds = np.arange(21)\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Create the colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax2, ticks=np.arange(0.5, 20))\n",
    "\n",
    "c_labels = [\n",
    "    \"0 - Base\", \"0 - Aux\",\n",
    "    \"1 - Base\", \"1 - Aux\",\n",
    "    \"2 - Base\", \"2 - Aux\",\n",
    "    \"3 - Base\", \"3 - Aux\",\n",
    "    \"4 - Base\", \"4 - Aux\",\n",
    "    \"5 - Base\", \"5 - Aux\",\n",
    "    \"6 - Base\", \"6 - Aux\",\n",
    "    \"7 - Base\", \"7 - Aux\",\n",
    "    \"8 - Base\", \"8 - Aux\",\n",
    "    \"9 - Base\", \"9 - Aux\",\n",
    "]\n",
    "cbar.set_ticklabels(c_labels)\n",
    "cbar.set_label(\"Classes\")\n",
    "\n",
    "\n",
    "# Plot for contrast embeddings\n",
    "tab20 = plt.cm.get_cmap('tab20')\n",
    "color_dict = {i: tab20(i/20) for i in range(20)}\n",
    "\n",
    "scatter3a = ax3.scatter(contrast_tsne[:len(contrast_tsne)//2, 0], contrast_tsne[:len(contrast_tsne)//2, 1], c=[color_dict[label] for label in contrast_labels[:len(contrast_tsne)//2]])\n",
    "scatter3b = ax3.scatter(contrast_tsne[len(contrast_tsne)//2:, 0], contrast_tsne[len(contrast_tsne)//2:, 1], c=[color_dict[label] for label in contrast_labels[len(contrast_tsne)//2:]], marker=\"x\", s=30)\n",
    "ax3.set_title(f'Contrastive Model Embeddings (Accuracy: {round(contrast_acc*100, 2)}%)')\n",
    "ax3.set_xlabel('t-SNE feature 1')\n",
    "ax3.set_ylabel('t-SNE feature 2')\n",
    "colors = [color_dict[i] for i in range(20)]\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "bounds = np.arange(21)\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Create the colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax3, ticks=np.arange(0.5, 20))\n",
    "\n",
    "c_labels = [\n",
    "    \"0 - Base\", \"0 - Aux\",\n",
    "    \"1 - Base\", \"1 - Aux\",\n",
    "    \"2 - Base\", \"2 - Aux\",\n",
    "    \"3 - Base\", \"3 - Aux\",\n",
    "    \"4 - Base\", \"4 - Aux\",\n",
    "    \"5 - Base\", \"5 - Aux\",\n",
    "    \"6 - Base\", \"6 - Aux\",\n",
    "    \"7 - Base\", \"7 - Aux\",\n",
    "    \"8 - Base\", \"8 - Aux\",\n",
    "    \"9 - Base\", \"9 - Aux\",\n",
    "]\n",
    "cbar.set_ticklabels(c_labels)\n",
    "cbar.set_label(\"Classes\")\n",
    "\n",
    "fig.suptitle(f\"Base - {base.capitalize()} / Auxiliary - {aux.capitalize()}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'tsne_2d_{base}+{aux}.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Divergence Between Layers of the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = TinyCNN()\n",
    "base_model.load_state_dict(torch.load(f\"models_unet/base_classifier_{base}.pt\", weights_only=True))\n",
    "base_model.eval()\n",
    "\n",
    "mixed_model = TinyCNN()\n",
    "mixed_model.load_state_dict(torch.load(f\"models_unet/mixed_classifier_{base}+{aux}.pt\", weights_only=True))\n",
    "mixed_model.eval()\n",
    "\n",
    "contrast_body = TinyCNN_Headless()\n",
    "contrast_head = TinyCNN_Head()\n",
    "\n",
    "contrast_model = WrapperModelTrainHead(\n",
    "    body=contrast_body,\n",
    "    head=contrast_head\n",
    ")\n",
    "\n",
    "contrast_model.load_state_dict(torch.load(f\"models_unet/contrast_classifier_{base}+{aux}.pt\", weights_only=True))\n",
    "contrast_model.eval()\n",
    "\n",
    "base_model.to(DEVICE)\n",
    "mixed_model.to(DEVICE)\n",
    "contrast_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dswd_loss_test = {\n",
    "    \"base\": np.zeros((2, len(test_loader), 9)),\n",
    "    \"mixed\": np.zeros((2, len(test_loader), 9)),\n",
    "    \"contrast\": np.zeros((2, len(test_loader), 9)),\n",
    "}\n",
    "# 2 - base or mixed\n",
    "\n",
    "networks = {\n",
    "    \"base\": base_model,\n",
    "    \"mixed\": mixed_model,\n",
    "    \"contrast\": contrast_model,\n",
    "}\n",
    "\n",
    "for i, network in enumerate(networks.keys()):\n",
    "    print(f\"Starting network {network} : {i}/{len(networks)}\")\n",
    "    dswd_loss_base = run_dswd(\n",
    "        model=networks[network],\n",
    "        dataloader=test_loader,\n",
    "        layers=8,\n",
    "        device=DEVICE,\n",
    "        base_only=True\n",
    "    )\n",
    "    dswd_loss_test[network][0] = dswd_loss_base\n",
    "\n",
    "    dswd_loss_mixed = run_dswd(\n",
    "        model=networks[network],\n",
    "        dataloader=test_loader,\n",
    "        layers=8,\n",
    "        device=DEVICE,\n",
    "        base_only=False\n",
    "    )\n",
    "    dswd_loss_test[network][1] = dswd_loss_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dswd_loss_val = np.zeros((len(test_loader), 9))\n",
    "val_loader.dataset.unique_sources = True\n",
    "for i, (base, aux, label) in enumerate(val_loader):\n",
    "    base = base.to(DEVICE)\n",
    "\n",
    "    aux_outputs = aux_model(base)[:9]\n",
    "    contrast_outputs = contrast_model(base)[:9]\n",
    "    print(i)\n",
    "    for j, (aux_layer, contrast_layer)  in enumerate(zip(aux_outputs, contrast_outputs)):\n",
    "\n",
    "        aux_layer_flat = aux_layer.view(aux_layer.size(0), -1)\n",
    "        contrast_layer_flat = contrast_layer.view(contrast_layer.size(0), -1)\n",
    "\n",
    "        projnet = ProjNet(size=aux_layer_flat.size(1)).to(DEVICE)\n",
    "        op_projnet = optim.Adam(\n",
    "            projnet.parameters(),\n",
    "            lr=0.001, \n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "        dsw_loss = DSW(\n",
    "            encoder=None,\n",
    "            embedding_norm=1.0,\n",
    "            num_projections=1000,\n",
    "            projnet=projnet,\n",
    "            op_projnet=op_projnet\n",
    "        )\n",
    "\n",
    "        dswd_loss_val[i, j] += dsw_loss(\n",
    "            aux_layer_flat,\n",
    "            contrast_layer_flat\n",
    "        ) / aux_layer_flat.size(0)\n",
    "        # print(j, dswd_loss_val[j,i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
